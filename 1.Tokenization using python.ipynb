{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb2fcd4",
   "metadata": {},
   "source": [
    "### Perform word tokenization and sentence tokenization for the long paragragh using NLP libraries like:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8704e3cd",
   "metadata": {},
   "source": [
    "#### a. Tokenization using python inbuilt methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3df67d",
   "metadata": {},
   "source": [
    "#### b.Tokenization using Regular expression(REgEx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acfcda",
   "metadata": {},
   "source": [
    "#### c.Tokenization using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1250fb",
   "metadata": {},
   "source": [
    "#### d.Tokenization using spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ae201",
   "metadata": {},
   "source": [
    "#### e.Tokenization using keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e545624f",
   "metadata": {},
   "source": [
    "#### f.Check token is Alphabet/Punctuation/Number/currency or not using spacy and display appropriate messages for every token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b399f6",
   "metadata": {},
   "source": [
    "### a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4909e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                Version\n",
      "---------------------- ----------------\n",
      "annotated-types        0.6.0\n",
      "appdirs                1.4.4\n",
      "apturl                 0.5.2\n",
      "argon2-cffi            21.1.0\n",
      "attrs                  21.2.0\n",
      "Babel                  2.8.0\n",
      "backcall               0.2.0\n",
      "bcrypt                 3.2.0\n",
      "beautifulsoup4         4.10.0\n",
      "beniget                0.4.1\n",
      "bleach                 4.1.0\n",
      "blinker                1.4\n",
      "breezy                 3.2.1\n",
      "Brlapi                 0.8.3\n",
      "Brotli                 1.0.9\n",
      "certifi                2020.6.20\n",
      "chardet                4.0.0\n",
      "click                  8.0.3\n",
      "colorama               0.4.4\n",
      "command-not-found      0.3\n",
      "configobj              5.0.6\n",
      "cryptography           3.4.8\n",
      "cupshelpers            1.0\n",
      "cv                     1.0.0\n",
      "cycler                 0.11.0\n",
      "dacite                 1.8.1\n",
      "dbus-python            1.2.18\n",
      "decorator              4.4.2\n",
      "defer                  1.0.6\n",
      "defusedxml             0.7.1\n",
      "Deprecated             1.2.13\n",
      "distro                 1.7.0\n",
      "distro-info            1.1+ubuntu0.1\n",
      "dulwich                0.20.31\n",
      "duplicity              0.8.21\n",
      "entrypoints            0.4\n",
      "fastbencode            0.0.5\n",
      "fasteners              0.14.1\n",
      "fastimport             0.9.14\n",
      "fonttools              4.29.1\n",
      "fs                     2.4.12\n",
      "future                 0.18.2\n",
      "gast                   0.5.2\n",
      "gpg                    1.16.0\n",
      "html5lib               1.1\n",
      "htmlmin                0.1.12\n",
      "httplib2               0.20.2\n",
      "idna                   3.3\n",
      "ImageHash              4.3.1\n",
      "imbalanced-learn       0.11.0\n",
      "imblearn               0.0\n",
      "importlib-metadata     4.6.4\n",
      "ipykernel              6.7.0\n",
      "ipython                7.31.1\n",
      "ipython_genutils       0.2.0\n",
      "ipywidgets             6.0.0\n",
      "jedi                   0.18.0\n",
      "jeepney                0.7.1\n",
      "Jinja2                 3.0.3\n",
      "joblib                 1.3.2\n",
      "jsonschema             3.2.0\n",
      "jupyter-client         7.1.2\n",
      "jupyter-core           4.9.1\n",
      "jupyterlab-pygments    0.1.2\n",
      "keyring                23.5.0\n",
      "kiwisolver             1.3.2\n",
      "language-selector      0.1\n",
      "launchpadlib           1.10.16\n",
      "lazr.restfulclient     0.14.4\n",
      "lazr.uri               1.0.6\n",
      "llvmlite               0.41.1\n",
      "lockfile               0.12.2\n",
      "louis                  3.20.0\n",
      "lxml                   4.8.0\n",
      "lz4                    3.1.3+dfsg\n",
      "macaroonbakery         1.3.1\n",
      "Mako                   1.1.3\n",
      "MarkupSafe             2.0.1\n",
      "matplotlib             3.5.1\n",
      "matplotlib-inline      0.1.3\n",
      "monotonic              1.6\n",
      "more-itertools         8.10.0\n",
      "mpmath                 0.0.0\n",
      "multimethod            1.10\n",
      "nbclient               0.5.6\n",
      "nbconvert              6.4.0\n",
      "nbformat               5.1.3\n",
      "nest-asyncio           1.5.4\n",
      "netifaces              0.11.0\n",
      "networkx               3.2.1\n",
      "notebook               6.4.8\n",
      "numba                  0.58.1\n",
      "numpy                  1.25.2\n",
      "oauthlib               3.2.0\n",
      "olefile                0.46\n",
      "packaging              21.3\n",
      "pandas                 2.0.3\n",
      "pandocfilters          1.5.0\n",
      "paramiko               2.9.3\n",
      "parso                  0.8.1\n",
      "patiencediff           0.2.1\n",
      "patsy                  0.5.3\n",
      "pexpect                4.8.0\n",
      "phik                   0.12.3\n",
      "pickleshare            0.7.5\n",
      "Pillow                 9.0.1\n",
      "pip                    23.3\n",
      "ply                    3.11\n",
      "prometheus-client      0.9.0\n",
      "prompt-toolkit         3.0.28\n",
      "protobuf               3.12.4\n",
      "ptyprocess             0.7.0\n",
      "py                     1.10.0\n",
      "pycairo                1.20.1\n",
      "pycups                 2.0.1\n",
      "pydantic               2.5.1\n",
      "pydantic_core          2.14.3\n",
      "PyGithub               1.55\n",
      "Pygments               2.11.2\n",
      "PyGObject              3.42.1\n",
      "pygraphviz             1.7\n",
      "PyJWT                  2.3.0\n",
      "pymacaroons            0.13.0\n",
      "PyNaCl                 1.5.0\n",
      "pyparsing              2.4.7\n",
      "PyQt5                  5.15.6\n",
      "PyQt5-sip              12.9.1\n",
      "pyRFC3339              1.1\n",
      "pyrsistent             0.18.1\n",
      "python-apt             2.4.0+ubuntu2\n",
      "python-dateutil        2.8.2\n",
      "python-debian          0.1.43+ubuntu1.1\n",
      "python-gitlab          2.10.1\n",
      "pythran                0.10.0\n",
      "pytz                   2022.1\n",
      "PyWavelets             1.5.0\n",
      "pyxdg                  0.27\n",
      "PyYAML                 5.4.1\n",
      "pyzmq                  22.3.0\n",
      "reportlab              3.6.8\n",
      "requests               2.25.1\n",
      "requests-toolbelt      0.9.1\n",
      "scikit-learn           1.3.2\n",
      "scipy                  1.8.0\n",
      "seaborn                0.12.2\n",
      "SecretStorage          3.3.1\n",
      "Send2Trash             1.8.1b0\n",
      "setuptools             59.6.0\n",
      "six                    1.16.0\n",
      "soupsieve              2.3.1\n",
      "ssh-import-id          5.11\n",
      "statsmodels            0.14.0\n",
      "sympy                  1.9\n",
      "systemd-python         234\n",
      "tangled-up-in-unicode  0.2.0\n",
      "terminado              0.13.1\n",
      "testpath               0.5.0\n",
      "threadpoolctl          3.2.0\n",
      "tornado                6.1\n",
      "tqdm                   4.66.1\n",
      "traitlets              5.1.1\n",
      "typeguard              4.1.5\n",
      "typing_extensions      4.8.0\n",
      "tzdata                 2023.3\n",
      "ubuntu-advantage-tools 8001\n",
      "ubuntu-drivers-common  0.0.0\n",
      "ufoLib2                0.13.1\n",
      "ufw                    0.36.1\n",
      "unattended-upgrades    0.1\n",
      "unicodedata2           14.0.0\n",
      "urllib3                1.26.5\n",
      "usb-creator            0.3.7\n",
      "visions                0.7.5\n",
      "wadllib                1.3.6\n",
      "wcwidth                0.2.5\n",
      "webencodings           0.5.1\n",
      "wheel                  0.37.1\n",
      "widgetsnbextension     2.0.0\n",
      "wordcloud              1.9.2\n",
      "wrapt                  1.13.3\n",
      "xdg                    5\n",
      "xkit                   0.0.0\n",
      "ydata-profiling        4.6.1\n",
      "zipp                   1.0.0\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "453eaa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word token: ['There', 'are', 'multiple', 'ways', 'we', 'can', 'perform', 'tokenization', 'on', 'the', 'given', 'text', 'data.', 'We', 'will', 'be', 'considering']\n",
      "Sentence token: ['There are multiple ways we can perform tokenization on the given text data', ' We will be considering']\n"
     ]
    }
   ],
   "source": [
    "#tokenizaton = splits sentence to words\n",
    "text=\"\"\"There are multiple ways we can perform tokenization on the given text data. We will be considering\"\"\" \n",
    "word=text.split()         #split words\n",
    "sent=text.split(\".\")      #spilt sentence after .\n",
    "print(\"Word token:\",word)\n",
    "print('/n')\n",
    "print(\"Sentence token:\",sent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e0c69f",
   "metadata": {},
   "source": [
    "### b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe3a413c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word token: ['There', 'are', 'multiple', 'ways', 'we', 'can', 'perform', 'tokenization', 'on', 'the', 'given', 'text', 'data', 'We', 'will', 'be', 'considering']\n",
      "/n\n",
      "Sentence token: ['There are multiple ways we can perform tokenization on the given text data', ' We will be considering']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word= re.findall('[\\w]+',text) # FINDALL=\\w=[a-z,A-Z,0-9],+ is more than one occurenceof any in \\w\n",
    "sent=re.compile(\"[.]\") .split(text)\n",
    "print(\"Word token:\",word)\n",
    "print('/n')\n",
    "print(\"Sentence token:\",sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b1d91",
   "metadata": {},
   "source": [
    "### c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79c2bc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m965.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/student/.local/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/student/.local/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m974.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.12.25\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7451a403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/student/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk is string oriented\n",
    "import nltk\n",
    "nltk.download(\"punkt\") # download punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13df2e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word token: ['There', 'are', 'multiple', 'ways', 'we', 'can', 'perform', 'tokenization', 'on', 'the', 'given', 'text', 'data', '.', 'We', 'will', 'be', 'considering']\n",
      "/n\n",
      "Sentence token: ['There are multiple ways we can perform tokenization on the given text data.', 'We will be considering']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "word=word_tokenize(text)\n",
    "sent=sent_tokenize(text)\n",
    "print(\"Word token:\",word)\n",
    "print('/n')\n",
    "print(\"Sentence token:\",sent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e009ce3",
   "metadata": {},
   "source": [
    "### d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eda9771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy)\n",
      "  Downloading thinc-8.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/student/.local/lib/python3.10/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/student/.local/lib/python3.10/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (59.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from spacy) (21.3)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m942.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /home/student/.local/lib/python3.10/site-packages (from spacy) (1.25.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/student/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /home/student/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/student/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.3)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m981.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 kB\u001b[0m \u001b[31m982.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m985.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 kB\u001b[0m \u001b[31m978.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0mm\n",
      "\u001b[?25hDownloading thinc-8.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.3/922.3 kB\u001b[0m \u001b[31m980.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m985.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m991.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m981.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: cymem, wasabi, typer, spacy-loggers, spacy-legacy, smart-open, murmurhash, langcodes, cloudpathlib, catalogue, blis, srsly, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 smart-open-6.4.0 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.2 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b68a023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m978.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/student/.local/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.25.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (59.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/student/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/student/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /home/student/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/student/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.8.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/student/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/student/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/student/.local/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "addd3eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word token: ['There', 'are', 'multiple', 'ways', 'we', 'can', 'perform', 'tokenization', 'on', 'the', 'given', 'text', 'data', '.', 'We', 'will', 'be', 'considering']\n",
      "/n\n",
      "Sentence token: ['There are multiple ways we can perform tokenization on the given text data.', 'We will be considering']\n"
     ]
    }
   ],
   "source": [
    "#spacy is object oriented: here class is language(text) and 2 objects vocab and DOC(used in tokenization) ie the text is tokenized by en core web sm to genarate o/p in DOC format\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') # en= english ,webpage, sm= smaill size\n",
    "doc= nlp(text)\n",
    "word=[]            #identifying the words\n",
    "for t in doc: \n",
    "    word.append(t.text)# appendingwords in empty word list \n",
    "sent=[]            #identifying the sentence\n",
    "for t in doc.sents: \n",
    "    sent.append(t.text)\n",
    "print(\"Word token:\",word)\n",
    "print('/n')\n",
    "print(\"Sentence token:\",sent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13b249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10f13e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e439d8c",
   "metadata": {},
   "source": [
    "#### e.Tokenization using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e99058dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m641.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m631.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0 (from tensorflow)\n",
      "  Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/student/.local/lib/python3.10/site-packages (from tensorflow) (1.25.2)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m880.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/lib/python3/dist-packages (from tensorflow) (21.3)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/student/.local/lib/python3.10/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.13.3)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.35.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading google_auth-2.27.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.25.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m966.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m981.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading MarkupSafe-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.0)\n",
      "Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m951.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:13\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m905.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m979.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m978.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m978.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m980.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m978.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m982.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m973.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m591.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m973.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m998.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.35.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m981.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading google_auth-2.27.0-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.8/186.8 kB\u001b[0m \u001b[31m959.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m924.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m36m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m981.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m971.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading MarkupSafe-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m921.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, requests-oauthlib, pyasn1, protobuf, opt-einsum, ml-dtypes, MarkupSafe, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, werkzeug, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.4 absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.27.0 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.0 h5py-3.10.0 keras-2.15.0 libclang-16.0.6 markdown-3.5.2 ml-dtypes-0.2.0 opt-einsum-3.3.0 protobuf-4.23.4 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.35.0 termcolor-2.4.0 werkzeug-3.0.1\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26987185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word token: ['there', 'are', 'multiple', 'ways', 'we', 'can', 'perform', 'tokenization', 'on', 'the', 'given', 'text', 'data', 'we', 'will', 'be', 'considering']\n",
      "/n\n",
      "Sentence token: ['there are multiple ways we can perform tokenization on the given text data', ' we will be considering']\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "word= text_to_word_sequence(text)\n",
    "sent= text_to_word_sequence(text,split='.')# Eliminates all the punctuations and converts upper case texts to lower case\n",
    "print(\"Word token:\",word)\n",
    "print('/n')\n",
    "print(\"Sentence token:\",sent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d3f0b",
   "metadata": {},
   "source": [
    "### Check token is Alphabet/Punctuation/Number/currency or not using spacy and display appropriate messages for every token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "657bd20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "are \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "multiple \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "ways \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "we \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "can \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "perform \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "tokenization \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "on \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "the \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "given \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "text \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "data \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      ". \n",
      "is_alpha: False \n",
      "is_punct: True \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "We \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "will \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "be \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n",
      "considering \n",
      "is_alpha: True \n",
      "is_punct: False \n",
      "like_num: False \n",
      "is_currency: False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print(t,\"\\nis_alpha:\",t.is_alpha,\n",
    "         \"\\nis_punct:\",t.is_punct,\n",
    "         \"\\nlike_num:\",t.like_num,\n",
    "         \"\\nis_currency:\",t.is_currency,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb3086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
